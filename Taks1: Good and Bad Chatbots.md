# Good Chatbots and Bad Chatbots
**What are chatbots?
Chatbots are programme that is used to converse with users. 
At first, it was rule-based but today, we can see LLM-based chatbots that break up the limit of rule-based chatbots.
For example, rule-based chatbots were unable to reply to the unexpected questions, but LLM can do that.

**What chatbots can do
LLM-powered chatbots can help companies to deal with customer survices, be a companion for people etc.
There are many kinds of charbots - Customer Support Chatbots, Conversational/Companion Chatbots, Educational Chatbots, Productivity & Utility Chatbots and so on.
I will focus on the **Conversational/Companion Chatbots, however, it should be applied to general chatbots.

## Examples of Conversational Chatbots
	| Name | Description |
| ----------- | ----------- |
| Replika | AI friend designed for emotional support and companionship. |
| Character.AI | Lets users chat with fictional or historical personas. |
| ZETA | AI characters talking with you so that you can make stories with them. |
Mitsuku | Award-winning conversational chatbot known for witty banter. |

## Good Chatbots
- 1. Accuracy: I think the first feature for good chatbots is accuracy, which means chatbots get what I mean. 
- 2. Showing Emotions: Thoough it understands what I mean, it should show emotions to make the conversation feel engaging and joyable.
- 3. 24/7 Availability: Chatbots are always approachable whereas humans cannot always reply to us. 
- 4. Customization: We can direct chatbots to respond in a way we want to. As we talk more, they know more about us, and adapt to us more.

## Bad Chatbots
- 1. Privacy Intrusion: Chatbots can access to user information. Especially, conversational chatbots and users talk about private things, so it if use the data for the model, it can manipulate people. 
- 2. Dependancy: Conversational chatbots can replace human relationships and social activity. It should not replace human interaction but just assist human communication.
- 3. Harming People: Conversational chatbots may reflect our biased and harmful words, so it should not make people to do harmful things such as suicide or homicide. 
